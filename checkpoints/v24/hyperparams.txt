### TRAINING ###
batch_size = 64         # Sequences per batch
num_steps = 150         # Number of sequence steps per batch
lstm_size = 2048        # Size of hidden layers in LSTMs
num_layers = 2          # Number of LSTM layers
learning_rate = 0.001   # Learning rate
keep_prob = 0.5         # Dropout keep probability
epochs = 60
save_every_n = 5000     # Save every N iterations

Training loss: 0.1025